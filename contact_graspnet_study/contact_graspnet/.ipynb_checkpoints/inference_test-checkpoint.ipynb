{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9b9c342",
   "metadata": {},
   "source": [
    "## 1. module import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc6ab7a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-15 16:51:38.551081: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-03-15 16:51:39.063839: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2023-03-15 16:51:39.090369: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-15 16:51:39.090447: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 3080 computeCapability: 8.6\n",
      "coreClock: 1.74GHz coreCount: 68 deviceMemorySize: 9.78GiB deviceMemoryBandwidth: 707.88GiB/s\n",
      "2023-03-15 16:51:39.090462: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-03-15 16:51:39.091965: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2023-03-15 16:51:39.092009: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2023-03-15 16:51:39.092531: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2023-03-15 16:51:39.092664: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2023-03-15 16:51:39.093137: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2023-03-15 16:51:39.093538: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2023-03-15 16:51:39.093605: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2023-03-15 16:51:39.093653: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-15 16:51:39.093729: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-15 16:51:39.093767: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/juju/contact_graspnet/pointnet2/tf_ops/sampling\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import numpy as np\n",
    "import time\n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_eager_execution()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath('/home/juju/contact_graspnet/contact_graspnet/inference.py')))\n",
    "sys.path.append(os.path.join(BASE_DIR))\n",
    "sys.path.append(os.path.join('/home/juju/contact_graspnet/contact_graspnet'))\n",
    "\n",
    "import config_utils\n",
    "from data import regularize_pc_point_count, depth2pc, load_available_input_data\n",
    "\n",
    "from contact_graspnet import contact_graspnet\n",
    "\n",
    "from contact_grasp_estimator import GraspEstimator\n",
    "from visualization_utils import visualize_grasps, show_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa669aa7",
   "metadata": {},
   "source": [
    "## 2. argument setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10460e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--ckpt_dir', default='checkpoints/scene_test_2048_bs3_hor_sigma_001', help='Log dir [default: checkpoints/scene_test_2048_bs3_hor_sigma_001]')\n",
    "parser.add_argument('--np_path', default='test_data/7.npy', help='Input data: npz/npy file with keys either \"depth\" & camera matrix \"K\" or just point cloud \"pc\" in meters. Optionally, a 2D \"segmap\"')\n",
    "parser.add_argument('--png_path', default='', help='Input data: depth map png in meters')\n",
    "parser.add_argument('--K', default=None, help='Flat Camera Matrix, pass as \"[fx, 0, cx, 0, fy, cy, 0, 0 ,1]\"')\n",
    "parser.add_argument('--z_range', default=[0.2,1.8], help='Z value threshold to crop the input point cloud')\n",
    "parser.add_argument('--local_regions', action='store_true', default=False, help='Crop 3D local regions around given segments.')\n",
    "parser.add_argument('--filter_grasps', action='store_true', default=False,  help='Filter grasp contacts according to segmap.')\n",
    "parser.add_argument('--skip_border_objects', action='store_true', default=False,  help='When extracting local_regions, ignore segments at depth map boundary.')\n",
    "parser.add_argument('--forward_passes', type=int, default=1,  help='Run multiple parallel forward passes to mesh_utils more potential contact points.')\n",
    "parser.add_argument('--segmap_id', type=int, default=0,  help='Only return grasps of the given object id')\n",
    "parser.add_argument('--arg_configs', nargs=\"*\", type=str, default=[], help='overwrite config parameters')\n",
    "\n",
    "FLAGS = parser.parse_args(args=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac367bb9",
   "metadata": {},
   "source": [
    "## 3. Config setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9eacf50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juju/contact_graspnet/contact_graspnet/config_utils.py:42: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  global_config = yaml.load(f)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'DATA': {'gripper_width': 0.08,\n",
       "  'input_normals': False,\n",
       "  'use_uniform_quaternions': False,\n",
       "  'train_on_scenes': True,\n",
       "  'labels': {'to_gpu': False,\n",
       "   'bin_weights': [0.16652107,\n",
       "    0.21488856,\n",
       "    0.37031708,\n",
       "    0.55618503,\n",
       "    0.75124664,\n",
       "    0.93943357,\n",
       "    1.07824539,\n",
       "    1.19423112,\n",
       "    1.55731375,\n",
       "    3.17161779],\n",
       "   'contact_gather': 'knn',\n",
       "   'filter_z': True,\n",
       "   'k': 1,\n",
       "   'max_radius': 0.005,\n",
       "   'min_unique_pos_contacts': 1,\n",
       "   'num_neg_contacts': 0,\n",
       "   'num_pos_contacts': 10000,\n",
       "   'offset_bins': [0,\n",
       "    0.00794435329,\n",
       "    0.0158887021,\n",
       "    0.0238330509,\n",
       "    0.0317773996,\n",
       "    0.0397217484,\n",
       "    0.0476660972,\n",
       "    0.055610446,\n",
       "    0.0635547948,\n",
       "    0.0714991435,\n",
       "    0.08],\n",
       "   'z_val': -0.1},\n",
       "  'raw_num_points': 20000,\n",
       "  'ndataset_points': 20000,\n",
       "  'num_point': 2048,\n",
       "  'sigma': 0.001,\n",
       "  'clip': 0.005,\n",
       "  'use_farthest_point': False,\n",
       "  'train_and_test': False,\n",
       "  'num_test_scenes': 1000,\n",
       "  'intrinsics': 'realsense',\n",
       "  'classes': None},\n",
       " 'LOSS': {'min_geom_loss_divisor': 1.0,\n",
       "  'max_geom_loss_divisor': 100.0,\n",
       "  'offset_loss_type': 'sigmoid_cross_entropy',\n",
       "  'too_small_offset_pred_bin_factor': 0,\n",
       "  'topk_confidence': 512},\n",
       " 'MODEL': {'bin_offsets': True,\n",
       "  'contact_distance_offset': True,\n",
       "  'dir_vec_length_offset': False,\n",
       "  'grasp_conf_head': {'conv1d': 1, 'dropout_keep': 0.5},\n",
       "  'grasp_dir_head': {'conv1d': 3, 'dropout_keep': 0.7},\n",
       "  'joint_head': {'conv1d': 4, 'dropout_keep': 0.7},\n",
       "  'joint_heads': False,\n",
       "  'larger_model': False,\n",
       "  'asymmetric_model': True,\n",
       "  'model': 'contact_graspnet',\n",
       "  'pointnet_fp_modules': [{'mlp': [256, 256]},\n",
       "   {'mlp': [256, 128]},\n",
       "   {'mlp': [128, 128, 128]}],\n",
       "  'pointnet_sa_module': {'group_all': True, 'mlp': [256, 512, 1024]},\n",
       "  'pointnet_sa_modules_msg': [{'mlp_list': [[32, 32, 64],\n",
       "     [64, 64, 128],\n",
       "     [64, 96, 128]],\n",
       "    'npoint': 2048,\n",
       "    'nsample_list': [32, 64, 128],\n",
       "    'radius_list': [0.02, 0.04, 0.08]},\n",
       "   {'mlp_list': [[64, 64, 128], [128, 128, 256], [128, 128, 256]],\n",
       "    'npoint': 512,\n",
       "    'nsample_list': [64, 64, 128],\n",
       "    'radius_list': [0.04, 0.08, 0.16]},\n",
       "   {'mlp_list': [[64, 64, 128], [128, 128, 256], [128, 128, 256]],\n",
       "    'npoint': 128,\n",
       "    'nsample_list': [64, 64, 128],\n",
       "    'radius_list': [0.08, 0.16, 0.32]}],\n",
       "  'pred_contact_approach': True,\n",
       "  'pred_contact_base': True,\n",
       "  'pred_contact_offset': True,\n",
       "  'pred_contact_success': True,\n",
       "  'pred_grasps_adds': False,\n",
       "  'pred_grasps_adds_gt2pred': False},\n",
       " 'OPTIMIZER': {'adds_gt2pred_loss_weight': 1,\n",
       "  'adds_loss_weight': 10,\n",
       "  'approach_cosine_loss_weight': 1,\n",
       "  'batch_size': 1,\n",
       "  'bn_decay_clip': 0.99,\n",
       "  'bn_decay_decay_rate': 0.5,\n",
       "  'bn_decay_decay_step': 200000,\n",
       "  'bn_init_decay': 0.5,\n",
       "  'decay_rate': 0.7,\n",
       "  'decay_step': 200000,\n",
       "  'dir_cosine_loss_weight': 1,\n",
       "  'learning_rate': 0.001,\n",
       "  'max_epoch': 16,\n",
       "  'momentum': 0.9,\n",
       "  'offset_loss_weight': 1,\n",
       "  'optimizer': 'adam',\n",
       "  'score_ce_loss_weight': 1},\n",
       " 'TEST': {'center_to_tip': 0.0,\n",
       "  'allow_zero_margin': 0,\n",
       "  'bin_vals': 'max',\n",
       "  'extra_opening': 0.005,\n",
       "  'first_thres': 0.23,\n",
       "  'second_thres': 0.18,\n",
       "  'max_farthest_points': 150,\n",
       "  'num_samples': 200,\n",
       "  'save': False,\n",
       "  'scale_fac': [1.25, 1.0, 0.75, 0.5],\n",
       "  'scales': False,\n",
       "  'with_replacement': False,\n",
       "  'filter_thres': 0.0001}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_config = config_utils.load_config(FLAGS.ckpt_dir, batch_size=FLAGS.forward_passes, arg_configs=FLAGS.arg_configs)\n",
    "\n",
    "# inference 시 사용할 batch_size이기 때문에 batch를 1로 셋팅한다. \n",
    "FLAGS.forward_passes\n",
    "\n",
    "global_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "926a585c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inference 시 사용할 batch_size이기 때문에 batch를 1로 셋팅한다. \n",
    "FLAGS.forward_passes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6529ee7c",
   "metadata": {},
   "source": [
    "###### config_utils.load_config 코드 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25b5dc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "\n",
    "def recursive_key_value_assign(d,ks,v):\n",
    "    \"\"\"\n",
    "    Recursive value assignment to a nested dict\n",
    "\n",
    "    Arguments:\n",
    "        d {dict} -- dict\n",
    "        ks {list} -- list of hierarchical keys\n",
    "        v {value} -- value to assign\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(ks) > 1:\n",
    "        recursive_key_value_assign(d[ks[0]],ks[1:],v)\n",
    "    elif len(ks) == 1:\n",
    "        d[ks[0]] = v\n",
    "        \n",
    "def load_config(checkpoint_dir, batch_size=None, max_epoch=None, data_path=None, arg_configs=[], save=False):\n",
    "    \"\"\"\n",
    "    Loads yaml config file and overwrites parameters with function arguments and --arg_config parameters\n",
    "\n",
    "    Arguments:\n",
    "        checkpoint_dir {str} -- Checkpoint directory where config file was copied to\n",
    "\n",
    "    Keyword Arguments:\n",
    "        batch_size {int} -- [description] (default: {None})\n",
    "        max_epoch {int} -- \"epochs\" (number of scenes) to train (default: {None})\n",
    "        data_path {str} -- path to scenes with contact grasp data (default: {None})\n",
    "        arg_configs {list} -- Overwrite config parameters by hierarchical command line arguments (default: {[]})\n",
    "        save {bool} -- Save overwritten config file (default: {False})\n",
    "\n",
    "    Returns:\n",
    "        [dict] -- Config\n",
    "    \"\"\"\n",
    "\n",
    "    config_path = os.path.join(checkpoint_dir, 'config.yaml')\n",
    "#     print(config_path)\n",
    "#     config_path = config_path if os.path.exists(config_path) else os.path.join(os.path.dirname(__file__),'config.yaml')\n",
    "    config_path = '/home/juju/contact_graspnet/checkpoints/scene_test_2048_bs3_hor_sigma_001/config.yaml'\n",
    "    with open(config_path,'r') as f:\n",
    "        global_config = yaml.load(f)\n",
    "\n",
    "    for conf in arg_configs:\n",
    "        k_str, v = conf.split(':')\n",
    "        try:\n",
    "            v = eval(v)\n",
    "        except:\n",
    "            pass\n",
    "        ks = [int(k) if k.isdigit() else k for k in k_str.split('.')]\n",
    "        \n",
    "        recursive_key_value_assign(global_config, ks, v)\n",
    "        \n",
    "    if batch_size is not None:\n",
    "        global_config['OPTIMIZER']['batch_size'] = int(batch_size)\n",
    "    if max_epoch is not None:\n",
    "        global_config['OPTIMIZER']['max_epoch'] = int(max_epoch)\n",
    "    if data_path is not None:\n",
    "        global_config['DATA']['data_path'] = data_path\n",
    "        \n",
    "    global_config['DATA']['classes'] = None\n",
    "    \n",
    "    if save:\n",
    "        with open(os.path.join(checkpoint_dir, 'config.yaml'),'w') as f:\n",
    "            yaml.dump(global_config, f)\n",
    "\n",
    "    return global_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1691eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19591/2857623346.py:42: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  global_config = yaml.load(f)\n"
     ]
    }
   ],
   "source": [
    "global_config = load_config(FLAGS.ckpt_dir, batch_size=FLAGS.forward_passes, arg_configs=FLAGS.arg_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66c41330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_dir = '/home/juju/contact_graspnet/checkpoints/scene_test_2048_bs3_hor_sigma_001/config.yaml'\n",
    "config_path = os.path.join(checkpoint_dir, 'config.yaml')\n",
    "\n",
    "os.path.exists(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a06f07a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(global_config, checkpoint_dir, input_paths, K=None, local_regions=True, skip_border_objects=False, filter_grasps=True, segmap_id=None, z_range=[0.2,1.8], forward_passes=1):\n",
    "    \"\"\"\n",
    "    Predict 6-DoF grasp distribution for given model and input data\n",
    "    \n",
    "    :param global_config: config.yaml from checkpoint directory\n",
    "    :param checkpoint_dir: checkpoint directory\n",
    "    :param input_paths: .png/.npz/.npy file paths that contain depth/pointcloud and optionally intrinsics/segmentation/rgb\n",
    "    :param K: Camera Matrix with intrinsics to convert depth to point cloud\n",
    "    :param local_regions: Crop 3D local regions around given segments. \n",
    "    :param skip_border_objects: When extracting local_regions, ignore segments at depth map boundary.\n",
    "    :param filter_grasps: Filter and assign grasp contacts according to segmap.\n",
    "    :param segmap_id: only return grasps from specified segmap_id.\n",
    "    :param z_range: crop point cloud at a minimum/maximum z distance from camera to filter out outlier points. Default: [0.2, 1.8] m\n",
    "    :param forward_passes: Number of forward passes to run on each point cloud. Default: 1\n",
    "    \"\"\"\n",
    "    \n",
    "    # Build the model\n",
    "    grasp_estimator = GraspEstimator(global_config)\n",
    "    grasp_estimator.build_network()\n",
    "\n",
    "    # Add ops to save and restore all the variables.\n",
    "    saver = tf.train.Saver(save_relative_paths=True)\n",
    "\n",
    "    # Create a session\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    config.allow_soft_placement = True\n",
    "    sess = tf.Session(config=config)\n",
    "\n",
    "    # Load weights\n",
    "    grasp_estimator.load_weights(sess, saver, checkpoint_dir, mode='test')\n",
    "    \n",
    "    os.makedirs('results', exist_ok=True)\n",
    "\n",
    "    # Process example test scenes\n",
    "    for p in glob.glob(input_paths):\n",
    "        print('Loading ', p)\n",
    "\n",
    "        pc_segments = {}\n",
    "        segmap, rgb, depth, cam_K, pc_full, pc_colors = load_available_input_data(p, K=K)\n",
    "        \n",
    "        if segmap is None and (local_regions or filter_grasps):\n",
    "            raise ValueError('Need segmentation map to extract local regions or filter grasps')\n",
    "\n",
    "        if pc_full is None:\n",
    "            print('Converting depth to point cloud(s)...')\n",
    "            pc_full, pc_segments, pc_colors = grasp_estimator.extract_point_clouds(depth, cam_K, segmap=segmap, rgb=rgb,\n",
    "                                                                                    skip_border_objects=skip_border_objects, z_range=z_range)\n",
    "\n",
    "        print('Generating Grasps...')\n",
    "        pred_grasps_cam, scores, contact_pts, _ = grasp_estimator.predict_scene_grasps(sess, pc_full, pc_segments=pc_segments, \n",
    "                                                                                          local_regions=local_regions, filter_grasps=filter_grasps, forward_passes=forward_passes)  \n",
    "\n",
    "        # Save results\n",
    "        np.savez('results/predictions_{}'.format(os.path.basename(p.replace('png','npz').replace('npy','npz'))), \n",
    "                  pred_grasps_cam=pred_grasps_cam, scores=scores, contact_pts=contact_pts)\n",
    "\n",
    "        # Visualize results          \n",
    "        show_image(rgb, segmap)\n",
    "        visualize_grasps(pc_full, pred_grasps_cam, scores, plot_opencv_cam=True, pc_colors=pc_colors)\n",
    "        \n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258b47ff",
   "metadata": {},
   "source": [
    "## inference 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea65199f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'contact_graspnet.contact_graspnet' from '/home/juju/contact_graspnet/contact_graspnet/contact_graspnet.py'>\n",
      "--- Get model\n",
      "WARNING:tensorflow:From /home/juju/anaconda3/envs/contact_graspnet/lib/python3.8/site-packages/tensorflow/python/keras/layers/normalization.py:534: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juju/anaconda3/envs/contact_graspnet/lib/python3.8/site-packages/tensorflow/python/keras/legacy_tf_layers/normalization.py:307: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
      "  warnings.warn(\n",
      "/home/juju/anaconda3/envs/contact_graspnet/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1692: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/juju/anaconda3/envs/contact_graspnet/lib/python3.8/site-packages/tensorflow/python/util/deprecation.py:602: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n",
      "WARNING:tensorflow:From /home/juju/anaconda3/envs/contact_graspnet/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:206: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pointclouds_pl': <tf.Tensor 'Placeholder:0' shape=(1, 20000, 3) dtype=float32>,\n",
       " 'cam_poses_pl': <tf.Tensor 'Placeholder_2:0' shape=(1, 4, 4) dtype=float32>,\n",
       " 'scene_idx_pl': <tf.Tensor 'Placeholder_1:0' shape=() dtype=int32>,\n",
       " 'is_training_pl': <tf.Tensor 'Placeholder_3:0' shape=() dtype=bool>,\n",
       " 'grasp_dir_pred': <tf.Tensor 'l2_normalize:0' shape=(1, 2048, 3) dtype=float32>,\n",
       " 'binary_seg_head': <tf.Tensor 'fc2_seg/BiasAdd:0' shape=(1, 2048, 1) dtype=float32>,\n",
       " 'binary_seg_pred': <tf.Tensor 'Sigmoid:0' shape=(1, 2048, 1) dtype=float32>,\n",
       " 'grasp_offset_head': <tf.Tensor 'fc2_off/BiasAdd:0' shape=(1, 2048, 10) dtype=float32>,\n",
       " 'grasp_offset_pred': <tf.Tensor 'Sigmoid_1:0' shape=(1, 2048, 10) dtype=float32>,\n",
       " 'approach_dir_pred': <tf.Tensor 'l2_normalize_1:0' shape=(1, 2048, 3) dtype=float32>,\n",
       " 'pred_points': <tf.Tensor 'layer1/GatherPoint:0' shape=(1, 2048, 3) dtype=float32>,\n",
       " 'offset_pred_idcs_pc': <tf.Tensor 'ArgMax_1:0' shape=(1, 2048) dtype=int64>,\n",
       " 'offset_bin_pred_vals': <tf.Tensor 'GatherNd:0' shape=(1, 2048) dtype=float32>,\n",
       " 'grasp_preds': <tf.Tensor 'concat_2:0' shape=(1, 2048, 4, 4) dtype=float32>,\n",
       " 'step': <tf.Variable 'Variable:0' shape=() dtype=int32>,\n",
       " 'end_points': {'grasp_dir_head': <tf.Tensor 'l2_normalize:0' shape=(1, 2048, 3) dtype=float32>,\n",
       "  'binary_seg_head': <tf.Tensor 'fc2_seg/BiasAdd:0' shape=(1, 2048, 1) dtype=float32>,\n",
       "  'binary_seg_pred': <tf.Tensor 'Sigmoid:0' shape=(1, 2048, 1) dtype=float32>,\n",
       "  'grasp_offset_head': <tf.Tensor 'fc2_off/BiasAdd:0' shape=(1, 2048, 10) dtype=float32>,\n",
       "  'grasp_offset_pred': <tf.Tensor 'Sigmoid_1:0' shape=(1, 2048, 10) dtype=float32>,\n",
       "  'approach_dir_head': <tf.Tensor 'l2_normalize_1:0' shape=(1, 2048, 3) dtype=float32>,\n",
       "  'pred_points': <tf.Tensor 'layer1/GatherPoint:0' shape=(1, 2048, 3) dtype=float32>}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grasp_estimator = GraspEstimator(global_config)\n",
    "grasp_estimator.build_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "68fb0e78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pointclouds_pl': <tf.Tensor 'Placeholder:0' shape=(1, 20000, 3) dtype=float32>,\n",
       " 'scene_idx_pl': <tf.Tensor 'Placeholder_1:0' shape=() dtype=int32>,\n",
       " 'cam_poses_pl': <tf.Tensor 'Placeholder_2:0' shape=(1, 4, 4) dtype=float32>,\n",
       " 'is_training_pl': <tf.Tensor 'Placeholder_3:0' shape=() dtype=bool>}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grasp_estimator.placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4aa7b804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'contact_graspnet.contact_graspnet'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e78ce52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0d8dfd08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bin_offsets': True,\n",
       " 'contact_distance_offset': True,\n",
       " 'dir_vec_length_offset': False,\n",
       " 'grasp_conf_head': {'conv1d': 1, 'dropout_keep': 0.5},\n",
       " 'grasp_dir_head': {'conv1d': 3, 'dropout_keep': 0.7},\n",
       " 'joint_head': {'conv1d': 4, 'dropout_keep': 0.7},\n",
       " 'joint_heads': False,\n",
       " 'larger_model': False,\n",
       " 'asymmetric_model': True,\n",
       " 'model': 'contact_graspnet',\n",
       " 'pointnet_fp_modules': [{'mlp': [256, 256]},\n",
       "  {'mlp': [256, 128]},\n",
       "  {'mlp': [128, 128, 128]}],\n",
       " 'pointnet_sa_module': {'group_all': True, 'mlp': [256, 512, 1024]},\n",
       " 'pointnet_sa_modules_msg': [{'mlp_list': [[32, 32, 64],\n",
       "    [64, 64, 128],\n",
       "    [64, 96, 128]],\n",
       "   'npoint': 2048,\n",
       "   'nsample_list': [32, 64, 128],\n",
       "   'radius_list': [0.02, 0.04, 0.08]},\n",
       "  {'mlp_list': [[64, 64, 128], [128, 128, 256], [128, 128, 256]],\n",
       "   'npoint': 512,\n",
       "   'nsample_list': [64, 64, 128],\n",
       "   'radius_list': [0.04, 0.08, 0.16]},\n",
       "  {'mlp_list': [[64, 64, 128], [128, 128, 256], [128, 128, 256]],\n",
       "   'npoint': 128,\n",
       "   'nsample_list': [64, 64, 128],\n",
       "   'radius_list': [0.08, 0.16, 0.32]}],\n",
       " 'pred_contact_approach': True,\n",
       " 'pred_contact_base': True,\n",
       " 'pred_contact_offset': True,\n",
       " 'pred_contact_success': True,\n",
       " 'pred_grasps_adds': False,\n",
       " 'pred_grasps_adds_gt2pred': False}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_config['MODEL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e52e1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765f3f1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2b7924",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576a7a06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16821ba9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "190fcf11",
   "metadata": {},
   "source": [
    "## Acronym mesh_contacts 파일 뜯어보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f9513cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bowl = np.load('/home/juju/contact_graspnet/acronym/mesh_contacts/Bowl_fa23aa60ec51c8e4c40fe5637f0a27e1_0.0006927004766994205.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f758bd79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collisions\n",
      "valid_locations\n",
      "successful\n",
      "grasp_transform\n",
      "contact_points\n",
      "contact_directions\n",
      "contact_face_normals\n",
      "contact_offsets\n"
     ]
    }
   ],
   "source": [
    "for i in bowl:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e2c36ae6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# successful : grasp 성공인지아닌지\n",
    "np.where(bowl['successful'])\n",
    "# grasp을 위한 eef_pose\n",
    "bowl['grasp_transform']\n",
    "# gripper 손가락의 direction (내생각)  shape : 2x3\n",
    "bowl['contact_directions'] \n",
    "# gripper가 닿을 object의 face normal (확실치 않음)\n",
    "bowl['contact_face_normals'][0]\n",
    "# 모르겠네.. 코드 봐야할듯. \n",
    "bowl['contact_offsets']\n",
    "\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "contact_graspnet",
   "language": "python",
   "name": "contact_graspnet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
